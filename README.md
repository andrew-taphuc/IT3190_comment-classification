# Comment Classification - PhÃ¢n loáº¡i bÃ¬nh luáº­n Ä‘á»™c háº¡i

Dá»± Ã¡n nÃ y thá»±c hiá»‡n phÃ¢n loáº¡i bÃ¬nh luáº­n tiáº¿ng Viá»‡t thÃ nh hai lá»›p: **toxic** (Ä‘á»™c háº¡i) vÃ  **non_toxic** (khÃ´ng Ä‘á»™c háº¡i) sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh Machine Learning truyá»n thá»‘ng.

## ğŸ“ Cáº¥u trÃºc thÆ° má»¥c

```
comment-clf/
â”œâ”€â”€ data/                    # Dá»¯ liá»‡u
â”‚   â”œâ”€â”€ raw/                 # Dá»¯ liá»‡u thÃ´ tá»« ViHSD dataset
â”‚   â”‚   â”œâ”€â”€ train.csv        # Táº­p train gá»‘c (3 lá»›p: CLEAN/OFFENSIVE/HATE)
â”‚   â”‚   â”œâ”€â”€ validation.csv   # Táº­p validation gá»‘c
â”‚   â”‚   â””â”€â”€ test.csv         # Táº­p test gá»‘c
â”‚   â”œâ”€â”€ interim/             # Dá»¯ liá»‡u trung gian (Ä‘Ã£ chuyá»ƒn sang binary labels)
â”‚   â”‚   â”œâ”€â”€ train.csv        # Táº­p train (toxic/non_toxic)
â”‚   â”‚   â”œâ”€â”€ val.csv          # Táº­p validation (toxic/non_toxic)
â”‚   â”‚   â””â”€â”€ test.csv         # Táº­p test (toxic/non_toxic)
â”‚   â””â”€â”€ processed/           # Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c lÃ m sáº¡ch (sáºµn sÃ ng Ä‘á»ƒ train)
â”‚       â”œâ”€â”€ train.csv        # Táº­p train Ä‘Ã£ clean
â”‚       â”œâ”€â”€ val.csv          # Táº­p validation Ä‘Ã£ clean
â”‚       â””â”€â”€ test.csv         # Táº­p test Ä‘Ã£ clean
â”‚
â”œâ”€â”€ src/                     # Source code
â”‚   â”œâ”€â”€ 01_download_vihsd.py      # Táº£i dataset ViHSD tá»« HuggingFace
â”‚   â”œâ”€â”€ 02_make_binary_labels.py  # Chuyá»ƒn labels 3 lá»›p â†’ 2 lá»›p
â”‚   â”œâ”€â”€ 03_clean_text.py          # LÃ m sáº¡ch text
â”‚   â”œâ”€â”€ 04_train_ml_models.py     # So sÃ¡nh nhiá»u mÃ´ hÃ¬nh ML
â”‚   â”œâ”€â”€ train_toxic.py             # Train mÃ´ hÃ¬nh thá»±c táº¿ Ä‘á»ƒ sá»­ dá»¥ng
â”‚   â”œâ”€â”€ predict_toxic.py           # Dá»± Ä‘oÃ¡n text cÃ³ toxic hay khÃ´ng
â”‚   â””â”€â”€ text_cleaner.py            # Module chá»©a hÃ m lÃ m sáº¡ch text
â”‚
â”œâ”€â”€ notebooks/                # Jupyter notebooks
â”‚   â””â”€â”€ analysis.ipynb       # Notebook phÃ¢n tÃ­ch dá»¯ liá»‡u
â”‚
â”œâ”€â”€ outputs/                  # Káº¿t quáº£
â”‚   â””â”€â”€ model_comparison.csv  # Báº£ng so sÃ¡nh cÃ¡c mÃ´ hÃ¬nh
â”‚
â”œâ”€â”€ toxicity_pipeline.joblib  # MÃ´ hÃ¬nh Ä‘Ã£ train (Ä‘á»ƒ sá»­ dá»¥ng)
â”œâ”€â”€ toxicity_meta.json        # Metadata cá»§a mÃ´ hÃ¬nh
â””â”€â”€ README.md                 # File nÃ y
```

## ğŸ“ Giáº£i thÃ­ch cÃ¡c file

### ğŸ”„ Pipeline xá»­ lÃ½ dá»¯ liá»‡u (cháº¡y tuáº§n tá»±)

CÃ¡c file nÃ y táº¡o thÃ nh pipeline xá»­ lÃ½ dá»¯ liá»‡u tá»« raw â†’ processed, cáº§n cháº¡y theo thá»© tá»±:

#### `01_download_vihsd.py`
- **Má»¥c Ä‘Ã­ch**: Táº£i dataset ViHSD (Vietnamese Hate Speech Detection) tá»« HuggingFace
- **Input**: KhÃ´ng cÃ³ (táº£i trá»±c tiáº¿p tá»« HuggingFace)
- **Output**: `data/raw/train.csv`, `data/raw/validation.csv`, `data/raw/test.csv`
- **Chá»©c nÄƒng**: 
  - Táº£i dataset `uitnlp/vihsd` tá»« HuggingFace
  - Chuyá»ƒn Ä‘á»•i sang Ä‘á»‹nh dáº¡ng CSV vá»›i 2 cá»™t: `text` vÃ  `label`
  - Labels ban Ä‘áº§u lÃ  3 lá»›p: `CLEAN`, `OFFENSIVE`, `HATE`

#### `02_make_binary_labels.py`
- **Má»¥c Ä‘Ã­ch**: Chuyá»ƒn Ä‘á»•i labels tá»« 3 lá»›p sang 2 lá»›p (binary classification)
- **Input**: `data/raw/*.csv`
- **Output**: `data/interim/train.csv`, `data/interim/val.csv`, `data/interim/test.csv`
- **Chá»©c nÄƒng**:
  - `CLEAN` â†’ `non_toxic`
  - `OFFENSIVE` hoáº·c `HATE` â†’ `toxic`
  - LÆ°u vÃ o thÆ° má»¥c `interim/`

#### `03_clean_text.py`
- **Má»¥c Ä‘Ã­ch**: LÃ m sáº¡ch vÃ  chuáº©n hÃ³a text
- **Input**: `data/interim/*.csv`
- **Output**: `data/processed/train.csv`, `data/processed/val.csv`, `data/processed/test.csv`
- **Chá»©c nÄƒng**:
  - Sá»­ dá»¥ng hÃ m `clean_text()` tá»« module `text_cleaner.py`
  - Loáº¡i bá» URLs, mentions, hashtags
  - Chuáº©n hÃ³a Unicode, teen code, kÃ½ tá»± láº·p
  - XÃ³a cÃ¡c dÃ²ng trá»‘ng vÃ  duplicate
  - LÆ°u vÃ o thÆ° má»¥c `processed/` (sáºµn sÃ ng Ä‘á»ƒ train)

### ğŸ”¬ So sÃ¡nh mÃ´ hÃ¬nh

#### `04_train_ml_models.py`
- **Má»¥c Ä‘Ã­ch**: So sÃ¡nh hiá»‡u suáº¥t cá»§a nhiá»u mÃ´ hÃ¬nh ML khÃ¡c nhau
- **Input**: `data/processed/train.csv`, `data/processed/val.csv`, `data/processed/test.csv`
- **Output**: `outputs/model_comparison.csv` (báº£ng so sÃ¡nh metrics)
- **Chá»©c nÄƒng**:
  - Train vÃ  Ä‘Ã¡nh giÃ¡ 4 mÃ´ hÃ¬nh:
    - `MultinomialNB`: Naive Bayes
    - `LogisticRegression`: Há»“i quy logistic
    - `LinearSVM`: Support Vector Machine tuyáº¿n tÃ­nh
    - `RandomForest`: Random Forest
  - Sá»­ dá»¥ng TF-IDF vectorization (1-2 grams)
  - TÃ­nh toÃ¡n accuracy vÃ  macro F1-score trÃªn validation vÃ  test set
  - LÆ°u káº¿t quáº£ so sÃ¡nh vÃ o CSV Ä‘á»ƒ phÃ¢n tÃ­ch

### ğŸš€ Train vÃ  sá»­ dá»¥ng mÃ´ hÃ¬nh thá»±c táº¿

#### `train_toxic.py`
- **Má»¥c Ä‘Ã­ch**: Train mÃ´ hÃ¬nh thá»±c táº¿ Ä‘á»ƒ sá»­ dá»¥ng trong production
- **Input**: `data/processed/train.csv`, `data/processed/val.csv`, `data/processed/test.csv`
- **Output**: 
  - `toxicity_pipeline.joblib`: MÃ´ hÃ¬nh Ä‘Ã£ train (cÃ³ thá»ƒ load vÃ  sá»­ dá»¥ng)
  - `toxicity_meta.json`: Metadata cá»§a mÃ´ hÃ¬nh (threshold, metrics, config)
- **Chá»©c nÄƒng**:
  - Sá»­ dá»¥ng pipeline tá»‘i Æ°u: **word TF-IDF + char TF-IDF + LinearSVC + CalibratedClassifierCV**
  - Feature Union káº¿t há»£p word n-grams (1-2) vÃ  character n-grams (3-5)
  - CalibratedClassifierCV Ä‘á»ƒ cÃ³ `predict_proba()` (xÃ¡c suáº¥t)
  - LÆ°u mÃ´ hÃ¬nh vÃ  metadata Ä‘á»ƒ sá»­ dá»¥ng sau

#### `predict_toxic.py`
- **Má»¥c Ä‘Ã­ch**: Dá»± Ä‘oÃ¡n má»™t text cÃ³ toxic hay khÃ´ng
- **Input**: 
  - Model: `toxicity_pipeline.joblib`
  - Text: tá»« argument `--text` hoáº·c stdin
- **Output**: JSON vá»›i label, toxic_score, threshold
- **Chá»©c nÄƒng**:
  - Load mÃ´ hÃ¬nh Ä‘Ã£ train
  - Dá»± Ä‘oÃ¡n text vÃ  tráº£ vá»:
    - `label`: "toxic" hoáº·c "non_toxic"
    - `toxic_score`: XÃ¡c suáº¥t toxic (0-1)
    - `threshold`: NgÆ°á»¡ng Ä‘á»ƒ phÃ¢n loáº¡i (máº·c Ä‘á»‹nh 0.7)

### ğŸ› ï¸ Module há»— trá»£

#### `text_cleaner.py`
- **Má»¥c Ä‘Ã­ch**: Module chá»©a hÃ m `clean_text()` Ä‘á»ƒ lÃ m sáº¡ch text
- **Chá»©c nÄƒng**:
  - Chuáº©n hÃ³a Unicode (NFC)
  - Loáº¡i bá» URLs, mentions (@user), hashtags (#tag)
  - Chuáº©n hÃ³a kÃ½ tá»± láº·p (vÃ­ dá»¥: "Ä‘áº¹pppp" â†’ "Ä‘áº¹pp")
  - Map teen code sang tá»« chuáº©n (vÃ­ dá»¥: "ko" â†’ "khÃ´ng", "vcl" â†’ "ráº¥t")
  - Giá»¯ láº¡i chá»‰ kÃ½ tá»± tiáº¿ng Viá»‡t, sá»‘, vÃ  dáº¥u cÃ¢u cÆ¡ báº£n
  - Loáº¡i bá» khoáº£ng tráº¯ng thá»«a
- **LÆ°u Ã½**: Module nÃ y Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ cÃ³ thá»ƒ pickle Ä‘Æ°á»£c khi lÆ°u mÃ´ hÃ¬nh vá»›i joblib

## ğŸ—‘ï¸ File Ä‘Ã£ xÃ³a

CÃ¡c file sau Ä‘Ã£ Ä‘Æ°á»£c xÃ³a vÃ¬ khÃ´ng Ä‘Æ°á»£c sá»­ dá»¥ng:
- `src/utils_text.py`: Chá»©a hÃ m `normalize_teencode()` nhÆ°ng Ä‘Ã£ cÃ³ trong `text_cleaner.py`
- `data/raw/comment.csv`: File khÃ´ng Ä‘Æ°á»£c sá»­ dá»¥ng trong pipeline

## ğŸš€ HÆ°á»›ng dáº«n cháº¡y

### BÆ°á»›c 1: CÃ i Ä‘áº·t dependencies

```bash
pip install pandas scikit-learn datasets joblib
```

### BÆ°á»›c 2: Xá»­ lÃ½ dá»¯ liá»‡u (Pipeline)

Cháº¡y cÃ¡c script theo thá»© tá»± Ä‘á»ƒ xá»­ lÃ½ dá»¯ liá»‡u tá»« raw â†’ processed:

```bash
# BÆ°á»›c 1: Táº£i dataset ViHSD
cd src
python 01_download_vihsd.py

# BÆ°á»›c 2: Chuyá»ƒn labels sang binary (toxic/non_toxic)
python 02_make_binary_labels.py

# BÆ°á»›c 3: LÃ m sáº¡ch text
python 03_clean_text.py
```

Sau khi cháº¡y xong, báº¡n sáº½ cÃ³ dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½ trong `data/processed/`.

### BÆ°á»›c 3: So sÃ¡nh mÃ´ hÃ¬nh (TÃ¹y chá»n)

Äá»ƒ so sÃ¡nh hiá»‡u suáº¥t cá»§a nhiá»u mÃ´ hÃ¬nh ML:

```bash
python 04_train_ml_models.py
```

Káº¿t quáº£ sáº½ Ä‘Æ°á»£c lÆ°u trong `outputs/model_comparison.csv`.

### BÆ°á»›c 4: Train mÃ´ hÃ¬nh thá»±c táº¿

Train mÃ´ hÃ¬nh Ä‘á»ƒ sá»­ dá»¥ng trong production:

```bash
python train_toxic.py
```

Hoáº·c vá»›i cÃ¡c tÃ¹y chá»n:

```bash
# Chá»‰ Ä‘á»‹nh thÆ° má»¥c dá»¯ liá»‡u
python train_toxic.py --data_dir ../data/processed

# TÃ¹y chá»‰nh tham sá»‘ C (regularization)
python train_toxic.py --C 1.5

# TÃ¹y chá»‰nh threshold
python train_toxic.py --threshold 0.65
```

Sau khi train xong, báº¡n sáº½ cÃ³:
- `toxicity_pipeline.joblib`: MÃ´ hÃ¬nh Ä‘Ã£ train
- `toxicity_meta.json`: Metadata cá»§a mÃ´ hÃ¬nh

### BÆ°á»›c 5: Sá»­ dá»¥ng mÃ´ hÃ¬nh Ä‘á»ƒ dá»± Ä‘oÃ¡n

#### CÃ¡ch 1: Dá»± Ä‘oÃ¡n tá»« argument

```bash
python predict_toxic.py --text "BÃ¬nh luáº­n cáº§n kiá»ƒm tra á»Ÿ Ä‘Ã¢y"
```

#### CÃ¡ch 2: Dá»± Ä‘oÃ¡n tá»« stdin

```bash
echo "BÃ¬nh luáº­n cáº§n kiá»ƒm tra" | python predict_toxic.py
```

#### CÃ¡ch 3: Dá»± Ä‘oÃ¡n vá»›i threshold tÃ¹y chá»‰nh

```bash
python predict_toxic.py --text "BÃ¬nh luáº­n" --threshold 0.6
```

#### Output máº«u:

```json
{
  "label": "toxic",
  "toxic_score": 0.85,
  "threshold": 0.7,
  "classes": ["non_toxic", "toxic"],
  "proba": [0.15, 0.85]
}
```

### VÃ­ dá»¥ workflow hoÃ n chá»‰nh

```bash
# 1. Xá»­ lÃ½ dá»¯ liá»‡u
cd src
python 01_download_vihsd.py
python 02_make_binary_labels.py
python 03_clean_text.py

# 2. So sÃ¡nh mÃ´ hÃ¬nh (tÃ¹y chá»n)
python 04_train_ml_models.py

# 3. Train mÃ´ hÃ¬nh thá»±c táº¿
python train_toxic.py

# 4. Test dá»± Ä‘oÃ¡n
python predict_toxic.py --text "ÄÃ¢y lÃ  má»™t bÃ¬nh luáº­n Ä‘á»™c háº¡i"
```

## ğŸ“Š Káº¿t quáº£ mÃ´ hÃ¬nh

MÃ´ hÃ¬nh sá»­ dá»¥ng pipeline: **word TF-IDF + char TF-IDF + LinearSVC + CalibratedClassifierCV**

- **Validation macro F1**: ~0.80
- **Test macro F1**: ~0.79
- **Validation accuracy**: ~0.89
- **Test accuracy**: ~0.89

## ğŸ“Œ LÆ°u Ã½

1. **Thá»© tá»± cháº¡y**: CÃ¡c file `01_`, `02_`, `03_` pháº£i cháº¡y theo thá»© tá»±
2. **Dá»¯ liá»‡u**: Dataset ViHSD Ä‘Æ°á»£c táº£i tá»± Ä‘á»™ng tá»« HuggingFace, khÃ´ng cáº§n táº£i thá»§ cÃ´ng
3. **Model**: MÃ´ hÃ¬nh Ä‘Æ°á»£c lÆ°u dÆ°á»›i dáº¡ng `.joblib` vÃ  cÃ³ thá»ƒ load láº¡i Ä‘á»ƒ sá»­ dá»¥ng
4. **Text cleaning**: HÃ m `clean_text()` Ä‘Æ°á»£c tÃ­ch há»£p vÃ o pipeline, nÃªn text input sáº½ tá»± Ä‘á»™ng Ä‘Æ°á»£c lÃ m sáº¡ch khi predict

## ğŸ”§ TÃ¹y chá»‰nh

- **Threshold**: CÃ³ thá»ƒ Ä‘iá»u chá»‰nh threshold trong `toxicity_meta.json` hoáº·c qua argument `--threshold` khi predict
- **Model parameters**: CÃ³ thá»ƒ tÃ¹y chá»‰nh tham sá»‘ C (regularization) trong `train_toxic.py` qua argument `--C`
- **Text cleaning**: CÃ³ thá»ƒ chá»‰nh sá»­a hÃ m `clean_text()` trong `text_cleaner.py` Ä‘á»ƒ phÃ¹ há»£p vá»›i nhu cáº§u

